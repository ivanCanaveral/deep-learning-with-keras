{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1 (3, 3, 3, 64)\n",
      "block1_conv2 (3, 3, 64, 64)\n",
      "block2_conv1 (3, 3, 64, 128)\n",
      "block2_conv2 (3, 3, 128, 128)\n",
      "block3_conv1 (3, 3, 128, 256)\n",
      "block3_conv2 (3, 3, 256, 256)\n",
      "block3_conv3 (3, 3, 256, 256)\n",
      "block4_conv1 (3, 3, 256, 512)\n",
      "block4_conv2 (3, 3, 512, 512)\n",
      "block4_conv3 (3, 3, 512, 512)\n",
      "block5_conv1 (3, 3, 512, 512)\n",
      "block5_conv2 (3, 3, 512, 512)\n",
      "block5_conv3 (3, 3, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        filters, biases = layer.get_weights()\n",
    "        print(layer.name, filters.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the input image with three channels for red, green and blue, that each filter has a depth of three (here we are working with a channel-last format). We could visualize one filter as a plot with three images, one for each channel, or compress all three down to a single color image, or even just look at the first channel and assume the other channels will look the same. The problem is, we then have 63 other filters that we might like to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can enumerate the first six filters out of the 64 in the block and plot each of the three channels of each filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot first few filters\n",
    "n_filters, ix = 6, 1\n",
    "for i in range(n_filters):\n",
    "\t# get the filter\n",
    "\tf = filters[:, :, :, i]\n",
    "\t# plot each channel separately\n",
    "\tfor j in range(3):\n",
    "\t\t# specify subplot and turn of axis\n",
    "\t\tax = plt.subplot(n_filters, 3, ix)\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\t\t# plot filter channel in grayscale\n",
    "\t\tplt.imshow(f[:, :, j], cmap='gray')\n",
    "\t\tix += 1\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
